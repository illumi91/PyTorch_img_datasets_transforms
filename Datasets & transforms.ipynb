{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this function in the lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(data_sample, shape = (28, 28)):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(shape), cmap='gray')\n",
    "    plt.title('y = ' + data_sample[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2322ba783f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "\n",
    "import torch \n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"auxiliary\">Auxiliary Functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following function as components of a dataset object, in this section, you will review each of the components independently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The path to the csv file with the labels for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory=\"\"\n",
    "csv_file ='index.csv'\n",
    "csv_path=os.path.join(directory,csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the CSV file and convert it into a dataframe , using the Pandas function <code>read_csv()</code> . You can view the dataframe using the method head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ankle boot</td>\n",
       "      <td>img/fashion0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T-shirt</td>\n",
       "      <td>img/fashion1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T-shirt</td>\n",
       "      <td>img/fashion2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dress</td>\n",
       "      <td>img/fashion3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T-shirt</td>\n",
       "      <td>img/fashion4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category             image\n",
       "0  Ankle boot  img/fashion0.png\n",
       "1     T-shirt  img/fashion1.png\n",
       "2     T-shirt  img/fashion2.png\n",
       "3       Dress  img/fashion3.png\n",
       "4     T-shirt  img/fashion4.png"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name = pd.read_csv(csv_path)\n",
    "data_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column of the dataframe corresponds to the type of clothing. The second column is the name of the image file corresponding to the clothing. You can obtain the path of the first file by using the method  <code> <i>DATAFRAME</i>.iloc[0, 1]</code>. The first argument corresponds to the sample number, and the second input corresponds to the column index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: img/fashion0.png\n"
     ]
    }
   ],
   "source": [
    "# Get the value on location row 0, column 1 (Notice that index starts at 0)\n",
    "#rember this dataset has only 100 samples to make the download faster  \n",
    "print('File name:', data_name.iloc[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the class of the sample is in the first column, we can also obtain the class value as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: Ankle boot\n"
     ]
    }
   ],
   "source": [
    "# Get the value on location row 0, column 0 (Notice that index starts at 0.)\n",
    "\n",
    "print('y:', data_name.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, You can obtain the file name of the second image file and class type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: img/fashion1.png\n",
      "class or y: T-shirt\n"
     ]
    }
   ],
   "source": [
    "# Print out the file name and the class number of the element on row 1 (the second row)\n",
    "\n",
    "print('File name:', data_name.iloc[1, 1])\n",
    "print('class or y:', data_name.iloc[1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of samples corresponds to the number of rows in a dataframe. You can obtain the number of rows using the following lines of code. This will correspond the data attribute <code>len</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows:  60000\n"
     ]
    }
   ],
   "source": [
    "# Print out the total number of rows in traing dataset\n",
    "\n",
    "print('The number of rows: ', data_name.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"load_image\">Load Image</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the image, we need the directory and the image name. We can concatenate the variable <code>train_data_dir</code> with the name of the image stored in a Dataframe. Finally, we will store the result in the variable <code>image_name</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img/fashion1.png'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the directory path with file name\n",
    "\n",
    "image_name =data_name.iloc[1, 1]\n",
    "image_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can find the image path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img/fashion1.png'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path=os.path.join(directory,image_name)\n",
    "image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the function <code>Image.open</code> to store the image to the variable <code>image</code> and display the image and class ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the second training image\n",
    "\n",
    "image = Image.open(image_path)\n",
    "plt.imshow(image,cmap='gray', vmin=0, vmax=255)\n",
    "plt.title(data_name.iloc[1, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can repeat the process for the 20th image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 20th image\n",
    "\n",
    "image_name = data_name.iloc[19, 1]\n",
    "image_path=os.path.join(directory,image_name)\n",
    "image = Image.open(image_path)\n",
    "plt.imshow(image,cmap='gray', vmin=0, vmax=255)\n",
    "plt.title(data_name.iloc[19, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Create the dataset object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"data_class\">Create a Dataset Class</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use the components in the last section to build a dataset class and then create an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your own dataset object\n",
    "\n",
    "class Dataset(Dataset):\n",
    "\n",
    "    # Constructor\n",
    "    def __init__(self, csv_file, data_dir, transform=None):\n",
    "        \n",
    "        # Image directory\n",
    "        self.data_dir=data_dir\n",
    "        \n",
    "        # The transform is goint to be used on image\n",
    "        self.transform = transform\n",
    "        data_dircsv_file=os.path.join(self.data_dir,csv_file)\n",
    "        # Load the CSV file contians image info\n",
    "        self.data_name= pd.read_csv(data_dircsv_file)\n",
    "        \n",
    "        # Number of images in dataset\n",
    "        self.len=self.data_name.shape[0] \n",
    "    \n",
    "    # Get the length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Getter\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        # Image file path\n",
    "        img_name=os.path.join(self.data_dir,self.data_name.iloc[idx, 1])\n",
    "        # Open image file\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        # The class label for the image\n",
    "        y = self.data_name.iloc[idx, 0]\n",
    "        \n",
    "        # If there is any transform method, apply it onto the image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset objects\n",
    "\n",
    "dataset = Dataset(csv_file=csv_file, data_dir=directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample of the image and the class y is stored in a tuple <code> dataset[sample]</code> . The image is the first element in the tuple <code> dataset[sample][0]</code> the label or class is the second element in the tuple <code> dataset[sample][1]</code>. For example you can plot the first image and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=dataset[0][0]\n",
    "y=dataset[0][1]\n",
    "\n",
    "plt.imshow(image,cmap='gray', vmin=0, vmax=255)\n",
    "plt.title(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you can plot the second image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=dataset[9][0]\n",
    "y=dataset[9][1]\n",
    "\n",
    "plt.imshow(image,cmap='gray', vmin=0, vmax=255)\n",
    "plt.title(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Torchvision\"> Torchvision Transforms  </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "You will focus on the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply some image transform functions on the dataset object. The iamge can be cropped and converted to a tensor. We can use <code>transform.Compose</code> we learned from the previous lab to combine the two transform functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two transforms: crop and convert to tensor. Apply the compose to MNIST dataset\n",
    "\n",
    "croptensor_data_transform = transforms.Compose([transforms.CenterCrop(20), transforms.ToTensor()])\n",
    "dataset = Dataset(csv_file=csv_file , data_dir=directory,transform=croptensor_data_transform )\n",
    "print(\"The shape of the first element tensor: \", dataset[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the image is now 20 x 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the first image again. Notice we see less of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first element in the dataset\n",
    "\n",
    "show_data(dataset[0],shape = (20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the second element in the dataset\n",
    "\n",
    "show_data(dataset[1],shape = (20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below example, we Vertically flip the image, and then convert it to a tensor. Use <code>transforms.Compose()</code> to combine these two transform functions. Plot the flipped image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the compose. Apply it on MNIST dataset. Plot the image out.\n",
    "\n",
    "fliptensor_data_transform = transforms.Compose([transforms.RandomVerticalFlip(p=1),transforms.ToTensor()])\n",
    "dataset = Dataset(csv_file=csv_file , data_dir=directory,transform=fliptensor_data_transform )\n",
    "show_data(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
